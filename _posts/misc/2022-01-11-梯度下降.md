# 梯度下降

机器学习的过程实际上是求损失函数的最小值。

比如，求这个函数的最小值：

$f(x) = 4x^2+5x+1$

它的导数是：$\dot{f(x)} = 8x+5$

易知，让导数为零的$x$就对应$f(x)$的最小值，所以$x=-5/8$。

但是，在实际情况下，没有办法求出解析解，所以只能使用梯度下降进行迭代。

首先初始化一个$x^1$，然后定义一个超参——学习率$\eta$

$for t in 1, 2, 3, ...:$

$x^{t+1} = x^t-\eta \nabla f(x)$

![img](https://gitee.com/solarwindrider/SolarWindRider/raw/main/assets/images/pics/lr01.png)

![img](https://gitee.com/solarwindrider/SolarWindRider/raw/main/assets/images/pics/lr02.png)
